%!TEX root = ../main.tex
\section{Introduction}
An abiding, key question in empirical finance is the following: which factors are useful for explaining the time series and cross-section behavior of equity and portfolio returns? There is by now a vast literature on this topic concerned with the development of possible factors and the empirical evaluation of those factors. 
Along with the original market factor introduced in \cite{sharpe1964capital} and \cite{lintner1965valuation}, an array of new factors have emerged as documented in \cite{harvey2015and}. 
Determining the empirical relevance of these factors is an ongoing statistical challenge and different avenues continue to be energetically explored. 
For instance, \cite{hou2014comparison} compare the \cite{hou2014digesting} and   \cite{fama2015five} five-factor models based on the conceptual understanding of factors and the ability of the factors to explain asset-pricing anomalies.  
A more statistical evaluation is provided by \cite{harvey2015lucky} who start with a collection of 12 leading factors and use a bootstrap procedure to forward select relevant factors. 
Stepwise selection, however, does not necessarily asymptotically produce the best model. 
This is particularly true in the presence of redundant factors (see \cite{judd2011data}). 

Our goal in this paper is to offer a quite different method for finding the best collection of factors. 
Our starting point is the recognition that the proper evaluation of the worth of a factor has to be in the context of models with and without other factors. 
Thus, basing a decision of the importance of a factor based solely on the t-statistic, or related statistics, ignores the question of joint significance and correlation between factors. 
Instead, answering the relevance question requires the consideration of all possible subset models, where the subset models are essentially special cases of a seemingly unrelated regression (SUR) model with the same subset of factors on the right-hand side but with different asset-specific factor coefficients, and a jointly distributed vector error with an unknown precision matrix. Restricting ourselves to 12 factors (10 from \cite{harvey2015lucky} and 2 additional ones), 
  and an intercept which can be present or absent in each possible case, leads to $2^{13}$ possible SUR models, which along with 6 different assumptions about the error distribution, amounts to the comparison of 49152 SUR models.
  
Our next innovation is to utilize a carefully crafted Bayesian approach to implement the comparison of these disparate models. Careful in this context means that the prior distribution is not placed independently on each factor, since we recognize that the meaning and importance of the factor coefficients and the error precision matrix vary by model. 
Each of the required 49152 different prior distributions are specified in an automatic and importantly, objective fashion, by employing a small training sample that precedes our estimation sample. 
Careful also refers to the use of a SUR type model in which error distribution and error precision are also viewed as unknowns that have to be inferred.

Decisions about the best model are then taken by the comparison of Bayesian marginal likelihoods, computed readily by the method of \cite{chib1995marginal}, for each of these models. 
This comparison of our models by Bayesian marginal likelihoods has well-recognized theoretical properties (in a small simulation exercise we also document the excellent performance of the marginal likelihood criterion in picking the true model). 
In particular, marginal likelihoods include a penalty for complexity. 
In other words, models with more factors do not necessarily gather greater support. 
In addition, models picked according to the marginal likelihoods, asymptotically pick either the true model, if it is in the class being considered, or find the model that is closet to the true model, if it is not in the class being considered. 
Our marginal likelihood based model exploration, therefore, provides an effective, previously unexplored avenue for evaluating the joint rather than individual importance of factors.


Our paper adds to the growing literature on the use of Bayesian techniques in finance.
\cite{avramov2002stock} and \cite{cremers2002stock}, for example, use Bayesian model-averaging to explore the question of market-return predictability with multiple predictors, while \cite{shanken1987bayesian}, \cite{harvey1990bayesian} and \cite{avramov2006exact} take a Bayesian approach to consider the question of the significance (or lack thereof) of the intercept in the CAPM context, providing a Bayesian alternative to the frequentist test of this hypothesis developed by \cite{gibbons1989test}.


\todo[inline]{Talk about results here!}

The rest of the paper unfolds as follows.
Section 1 describes the model with Student-t errors and the estimation framework. 
Section 2 provides a simulation example to motivate our research.
Section 4 describes the main results. 
Finally, section 5 concludes. 
Results for the model with normal errors and general description of the three block sample can be found in the Appendix.

